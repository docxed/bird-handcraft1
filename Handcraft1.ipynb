{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tqdm as t\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "import skimage.feature as skf\n",
    "import sklearn.neighbors as sn\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import os\n",
    "from skimage.feature import greycomatrix, greycoprops\n",
    "from skimage import io\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(pathOrigin):\n",
    "    \"Funtion สำหรับ Load Dataset\"\n",
    "    \n",
    "    data = []\n",
    "    lable = []\n",
    "    species = os.listdir(pathOrigin)\n",
    "    for _class in species:\n",
    "        if _class == '.' or _class == '..':\n",
    "            continue\n",
    "    #     print(_class)\n",
    "        for _img in os.listdir(pathOrigin + _class):\n",
    "            if _img == '.' or _img == '..':\n",
    "                continue\n",
    "            path = pathOrigin + _class + '\\\\' + _img\n",
    "            img = cv2.imread(path)\n",
    "            data.append(img)\n",
    "            lable.append(_class)\n",
    "    return data, lable\n",
    "# load training dataset\n",
    "train_data, train_label = load_dataset('C:\\\\Users\\\\akira\\\\Desktop\\\\Work\\\\bird-handcraft1\\\\archive\\\\train\\\\')\n",
    "train_num = len(train_label)\n",
    "# load testing dataset\n",
    "test_data, test_label = load_dataset('C:\\\\Users\\\\akira\\\\Desktop\\\\Work\\\\bird-handcraft1\\\\archive\\\\test\\\\')\n",
    "test_num = len(test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hog_hist(data):\n",
    "    feature = []\n",
    "    # HOG's Parameter\n",
    "    winSize = (64,64)\n",
    "    blockSize = (16,16)\n",
    "    blockStride = (4,4)\n",
    "    cellSize = (8,8)\n",
    "    nbins = 16\n",
    "    derivAperture = 1\n",
    "    winSigma = 4.0\n",
    "    histogramNormType = 0\n",
    "    L2HysThreshold = 2.0000000000000001e-01\n",
    "    gammaCorrection = 0\n",
    "    nlevels = 64\n",
    "    winStride = (8,8)\n",
    "    padding = (8,8)\n",
    "    locations = ((10,20),)\n",
    "    hog = cv2.HOGDescriptor(winSize,blockSize,blockStride,cellSize,nbins,derivAperture,winSigma,histogramNormType,L2HysThreshold,gammaCorrection,nlevels)\n",
    "    for i in data:\n",
    "        hist = hog.compute(i,winStride,padding,locations)\n",
    "        feature.append(np.array(hist))\n",
    "    feature = np.array(feature)\n",
    "    return feature\n",
    "featureTr = hog_hist(train_data)\n",
    "featureTr = featureTr.reshape(train_num, -1)\n",
    "featureTs = hog_hist(test_data)\n",
    "featureTs = featureTs.reshape(test_num,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hsv_hist(data):\n",
    "    feature = []\n",
    "    for i in data:\n",
    "        # แปลงภาพให้อยู่บนปริภูมิสี HSV\n",
    "        out = cv2.cvtColor(i, cv2.COLOR_BGR2HSV)\n",
    "        # แปลงข้อมูลจากเมตริกซ์ให้อยู่ในรูปแบบเวกเตอร์ เฉพาะ Hue\n",
    "        out = out[:,:,0].reshape(1,-1);\n",
    "        # สร้างฮิสโตแกรมจาก Hue\n",
    "        hist, bins = np.histogram(out,bins = np.arange(-0.5,256,1) )\n",
    "        # Normalization เพื'อทําให้ Feature รสามารถรองรับขนาดภาพที'แตกต่างกันได้\n",
    "        feature.append([hist/np.sum(hist)])\n",
    "    feature = np.array(feature)\n",
    "    return feature\n",
    "featureTr2 = hsv_hist(train_data)\n",
    "featureTr2 = featureTr.reshape(train_num, -1)\n",
    "featureTs2 = hsv_hist(test_data)\n",
    "featureTs2 = featureTs.reshape(test_num,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm(data):\n",
    "    norm_data = preprocessing.normalize(data, axis=0)\n",
    "    return norm_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "normfeatureTr = norm(featureTr)\n",
    "normfeatureTr2 = norm(featureTr2)\n",
    "normfeatureTs = norm(featureTs)\n",
    "normfeatureTs2 = norm(featureTs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.concatenate((normfeatureTr, normfeatureTr2), axis=1)\n",
    "test_data = np.concatenate((normfeatureTs, normfeatureTs2), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=0.01, random_state=0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "clf = LinearSVC(random_state=0, C=0.01)\n",
    "clf.fit(train_data, train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = clf.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = 0.01 ,\t Accuracy: 7.6 %\n"
     ]
    }
   ],
   "source": [
    "print (\"C =\", 0.01, \",\\t Accuracy:\", np.mean(predict == test_label)*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.40824829, 0.18257419, 0.44232587],\n",
       "       [0.81649658, 0.36514837, 0.14744196],\n",
       "       [0.40824829, 0.91287093, 0.88465174]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = np.array([[100,10,3],\n",
    "                 [200,20,1], \n",
    "                 [100, 50, 6]])\n",
    "preprocessing.normalize(test, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 0.01 ,\t Accuracy: 15.6 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "neigh = KNeighborsClassifier(n_neighbors=1)\n",
    "neigh.fit(train_data, train_label)\n",
    "predict = neigh.predict(test_data)\n",
    "print (\"k =\", 0.01, \",\\t Accuracy:\", np.mean(predict == test_label)*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureTr[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_fea[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
